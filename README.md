# Gait-Based Biometric Recognition System

A comprehensive machine learning system for gait-based biometric recognition using accelerometer data. This project implements a complete pipeline from data preprocessing to model evaluation and visualization.

## ğŸš€ Features

- **Data Preprocessing**: Gait cycle segmentation, filtering, and normalization
- **Feature Extraction**: Comprehensive feature engineering (temporal, frequency, waveform, and phase features)
- **Multiple ML Models**: Support for various algorithms including Random Forest, SVM, Neural Networks, XGBoost, and Deep Learning
- **Visualization**: Interactive plots and comprehensive analysis tools
- **Evaluation**: Cross-validation and performance metrics
- **Synthetic Data**: Built-in synthetic data generation for testing and demonstration

## ğŸ“ Project Structure

```
biometrics/
â”œâ”€â”€ main.py                 # Main pipeline script
â”œâ”€â”€ data_preprocessing.py   # Data loading and preprocessing
â”œâ”€â”€ feature_extraction.py   # Feature engineering
â”œâ”€â”€ ml_models.py           # Machine learning models
â”œâ”€â”€ visualization.py       # Visualization tools
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ README.md             # This file
```

## ğŸ› ï¸ Installation

1. **Clone or download the project**
2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ¯ Quick Start

### Run the Complete Pipeline
```bash
python main.py
```

### Run Quick Demo
```bash
python main.py --quick
```

### Individual Module Usage

#### 1. Data Preprocessing
```python
from data_preprocessing import GaitDataPreprocessor, create_sample_dataset

# Create synthetic data
dataset = create_sample_dataset()

# Or use custom preprocessing
preprocessor = GaitDataPreprocessor(sampling_rate=50)
raw_data = preprocessor.load_synthetic_data(n_subjects=30, n_samples_per_subject=50)
segmented_data = preprocessor.segment_gait_cycles(raw_data)
normalized_data = preprocessor.normalize_cycles(segmented_data)
```

#### 2. Feature Extraction
```python
from feature_extraction import GaitFeatureExtractor

extractor = GaitFeatureExtractor()
features_df, labels = extractor.extract_features_from_dataset(dataset)
```

#### 3. Machine Learning Models
```python
from ml_models import GaitBiometricClassifier

classifier = GaitBiometricClassifier()
X_train, X_test, y_train, y_test = classifier.prepare_data(features_df, labels)
classifier.train_models(X_train, y_train)
results = classifier.evaluate_models(X_test, y_test)
```

#### 4. Visualization
```python
from visualization import GaitVisualizer

visualizer = GaitVisualizer()
visualizer.plot_gait_cycle(cycle_data, subject_id)
visualizer.plot_pca_visualization(features_df, labels)
```

## ğŸ”¬ Methodology

### Data Preprocessing
1. **Signal Filtering**: Low-pass Butterworth filter to remove noise
2. **Gait Cycle Detection**: Automatic heel strike detection
3. **Cycle Segmentation**: Individual gait cycle extraction
4. **Normalization**: Standardize cycle length to 100 data points

### Feature Extraction
- **Temporal Features**: Mean, std, skewness, kurtosis, RMS, energy, entropy
- **Frequency Features**: Spectral centroid, bandwidth, dominant frequency, power
- **Waveform Features**: Symmetry, regularity, smoothness, peak characteristics
- **Phase Features**: Stance/swing phase ratios, support phases

### Machine Learning Models
- Random Forest
- Support Vector Machine (SVM)
- K-Nearest Neighbors
- Gradient Boosting
- XGBoost
- LightGBM
- Neural Networks (MLP)
- Deep Learning (TensorFlow/Keras)
- Naive Bayes
- Logistic Regression

## ğŸ“Š Results

The system typically achieves:
- **Accuracy**: 85-95% on synthetic data
- **Cross-validation**: 5-fold stratified CV
- **Feature Selection**: Top 50 features using statistical tests

### Sample Output
```
Model Performance Summary:
==================================================
 1. Random Forest         : 0.9234 Â± 0.0234
 2. XGBoost              : 0.9156 Â± 0.0198
 3. LightGBM             : 0.9123 Â± 0.0256
 4. Gradient Boosting    : 0.9089 Â± 0.0212
 5. Neural Network       : 0.8956 Â± 0.0289
 6. SVM                  : 0.8876 Â± 0.0245
 7. Deep Learning        : 0.8845
 8. K-Nearest Neighbors  : 0.8234 Â± 0.0312
 9. Logistic Regression  : 0.7567 Â± 0.0345
10. Naive Bayes          : 0.7234 Â± 0.0298

ğŸ† Best Model: Random Forest with 0.9234 accuracy
```

## ğŸ¨ Visualization Features

- **Gait Cycle Plots**: Multi-component acceleration visualization
- **Feature Correlation**: Heatmap of feature relationships
- **PCA Visualization**: 2D/3D principal component analysis
- **t-SNE Visualization**: Non-linear dimensionality reduction
- **Model Performance**: Comparative bar charts
- **Interactive Plots**: Plotly-based interactive visualizations

## ğŸ”§ Configuration

Modify the configuration in `main.py`:

```python
config = {
    'n_subjects': 30,              # Number of subjects
    'n_samples_per_subject': 50,   # Gait cycles per subject
    'sampling_rate': 50,           # Hz
    'test_size': 0.2,              # Test set proportion
    'feature_selection_k': 50,     # Number of selected features
    'random_state': 42             # Reproducibility seed
}
```

## ğŸ“ˆ Real-World Application

### For Real Sensor Data:
1. **Replace synthetic data** with actual accelerometer/gyroscope data
2. **Adjust sampling rate** to match your sensor (typically 50-100 Hz)
3. **Calibrate sensors** for accurate measurements
4. **Validate on larger datasets** with diverse populations

### Deployment Considerations:
- **Real-time Processing**: Implement sliding window analysis
- **Feature Caching**: Store computed features for efficiency
- **Model Optimization**: Use lightweight models for mobile deployment
- **Privacy**: Implement secure biometric template storage

## ğŸ§ª Testing and Validation

### Synthetic Data Validation:
- The system includes synthetic data generation for testing
- Synthetic data mimics real gait characteristics
- Use for algorithm development and initial validation

### Real Data Integration:
```python
# Replace synthetic data loading with real data
def load_real_data(file_path):
    # Load your actual sensor data
    # Format: {'subject_id': [cycle_data, ...], ...}
    pass

# Update the main pipeline
raw_data = load_real_data('path/to/your/data.csv')
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- Machine learning algorithms from scikit-learn
- Deep learning implementation using TensorFlow/Keras
- Visualization tools from matplotlib, seaborn, and plotly
- Signal processing using scipy

## ğŸ“ Support

For questions or issues:
1. Check the documentation above
2. Review the code comments
3. Open an issue with detailed description
4. Include error messages and system information

---

**Note**: This system is designed for research and educational purposes. For production use, ensure proper validation with real-world data and consider security implications of biometric systems.
